{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load generic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('../tuner_utils')\n",
    "from robust_region_v2 import *\n",
    "sys.path.append('../scripts')\n",
    "from resnet_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model specific libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('../scripts')\n",
    "# from resnet import resnet_model\n",
    "# from resnet.resnet_main import train\n",
    "# from resnet import cifar_input\n",
    "import resnet_model\n",
    "from resnet_main import train\n",
    "import cifar_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function for constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(hps, dataset, train_data_path):\n",
    "    images, labels = cifar_input.build_input(\n",
    "      dataset, train_data_path, hps.batch_size, 'train')\n",
    "    model = resnet_model.ResNet(hps, images, labels, 'train')\n",
    "    model.build_graph()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define function to get a session for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def GetTrainingSession(model_train):\n",
    "#     mon_sess = tf.train.MonitoredTrainingSession(\n",
    "#       config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "#     return mon_sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define single step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_single_step_frame(sess, model_train, lr_val, mom_val, clip_norm_base):\n",
    "    feed_dict={model_train.lrn_rate: lr_val,\n",
    "               model_train.mom: mom_val,\n",
    "               model_train.clip_norm: clip_norm_base / lr_val}  # Sets learning rate        \n",
    "    output_results = sess.run( [model_train.cost, model_train.global_norm] + model_train.grads +[model_train.train_op, ], feed_dict=feed_dict)    \n",
    "    loss = output_results[0]\n",
    "    grad_norm = output_results[1]\n",
    "    grads = output_results[2:(2 + len(model_train.grads) ) ]\n",
    "    return grads, grad_norm, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up path and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 100\n",
    "TRAIN_DATA_PATH = '../../../cifar-100-binary/train.bin'\n",
    "TEST_DATA_PATH = '../../../cifar-100-binary/test.bin'\n",
    "MODE = 'train'\n",
    "LOG_ROOT='../results/resnet_model'\n",
    "DATASET='cifar100'\n",
    "DEV = '/gpu:0'\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct train model and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 32, 32, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:image after unit (128, 8, 8, 256)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1f51e3305ef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#     mon_sess = GetTrainingSession(model_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mgpu_mem_portion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mmodel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmon_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhps_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhps_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpu_mem_portion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATASET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST_DATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/lfs/raiders1/0/zjian/tuner/resnet/experiments/two_term_exp_smooth_bottleneck/scripts/resnet_utils.pyc\u001b[0m in \u001b[0;36msetup\u001b[1;34m(hps_train, hps_eval, gpu_mem_portion, DEV, DATASET, TRAIN_DATA_PATH, TEST_DATA_PATH)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhps_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhps_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpu_mem_portion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATASET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST_DATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mmodel_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhps_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATASET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# use the train for the scope name just for reuse the variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/lfs/raiders1/0/zjian/tuner/resnet/experiments/two_term_exp_smooth_bottleneck/scripts/resnet_utils.pyc\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(hps, dataset, train_data_path, mode)\u001b[0m\n\u001b[0;32m     25\u001b[0m       dataset, train_data_path, hps.batch_size, mode)\n\u001b[0;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/lfs/raiders1/0/zjian/tuner/resnet/experiments/two_term_exp_smooth_bottleneck/scripts/resnet_model.pyc\u001b[0m in \u001b[0;36mbuild_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_train_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/lfs/raiders1/0/zjian/tuner/resnet/experiments/two_term_exp_smooth_bottleneck/scripts/resnet_model.pyc\u001b[0m in \u001b[0;36m_build_train_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads_clip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_global_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[0;32m    480\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                 \u001b[0min_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.pyc\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    608\u001b[0m   \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m   return (array_ops.reshape(math_ops.reduce_sum(grad * y, rx), sx),\n\u001b[0m\u001b[0;32m    611\u001b[0m           array_ops.reshape(math_ops.reduce_sum(x * grad, ry), sy))\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    985\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1611\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m   \"\"\"\n\u001b[1;32m-> 1613\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1614\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    757\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    758\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2238\u001b[0m     ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,\n\u001b[0;32m   2239\u001b[0m                     \u001b[0mcontrol_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2240\u001b[1;33m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0m\u001b[0;32m   2241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2242\u001b[0m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1128\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;31m# Add this op to the current control flow context:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_extract_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mco_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mframe_globals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 100\n",
    "tf.set_random_seed(1)\n",
    "hps_train = resnet_model.HParams(batch_size=batch_size_train,\n",
    "                         num_classes=NUM_CLASSES,\n",
    "                         min_lrn_rate=0.0001,\n",
    "                         lrn_rate=0.1,\n",
    "                         mom=0.9,\n",
    "                         clip_norm_base=10.0,\n",
    "                         num_residual_units=5,\n",
    "                         use_bottleneck=True,\n",
    "                         weight_decay_rate=0.0002,\n",
    "                         relu_leakiness=0.1,\n",
    "                         optimizer='mom',\n",
    "                         model_scope='train')\n",
    "hps_eval = resnet_model.HParams(batch_size=batch_size_test,\n",
    "                         num_classes=NUM_CLASSES,\n",
    "                         min_lrn_rate=0.0001,\n",
    "                         lrn_rate=0.1,\n",
    "                         mom=0.9,\n",
    "                         clip_norm_base=10.0,\n",
    "                         num_residual_units=5,\n",
    "                         use_bottleneck=True,\n",
    "                         weight_decay_rate=0.0002,\n",
    "                         relu_leakiness=0.1,\n",
    "                         optimizer='mom',\n",
    "                         model_scope='train')\n",
    "\n",
    "\n",
    "# with tf.variable_scope(\"train\"), tf.device(DEV):\n",
    "#     model_train = get_model(hps_train, DATASET, TRAIN_DATA_PATH)\n",
    "\n",
    "#     init_op = tf.global_variables_initializer()\n",
    "#     mon_sess = GetTrainingSession(model_train)\n",
    "gpu_mem_portion=0.4\n",
    "model_train, model_eval, init_op, mon_sess = setup(hps_train, hps_eval, gpu_mem_portion, DEV, DATASET, TRAIN_DATA_PATH, TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general_log_dir = \"../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exp smooth 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_step = 40001\n",
    "display_interval=250\n",
    "test_interval=50000 # no test\n",
    "clip_norm_base = 100.0\n",
    "# the following a few params are all dummy and placeholder\n",
    "train_batch_size = 128\n",
    "grad_beta = 0.9\n",
    "dist_beta = 0.9\n",
    "curv_beta = 0.9\n",
    "param_beta = 0.999\n",
    "sliding_win_width=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_val = 0.1\n",
    "mom_val = 0.9\n",
    "do_pred = True\n",
    "log_dir = general_log_dir + \"/test0.1_0.9\"\n",
    "# log_dir = general_log_dir + \"/two_term_lr_\" + str(lr_val) + \"_mom_\" + str(mom_val) + \"_exp_0.99\"\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "mon_sess.run(init_op)\n",
    "\n",
    "train_single_step = lambda lr_val, mom_val, clip_norm_base: train_single_step_frame(mon_sess, model_train, lr_val, mom_val, clip_norm_base)\n",
    "\n",
    "loss_list, g_norm_list = train_rave_noisy_acc(mon_sess, model_eval, num_step, lr_val, mom_val, \n",
    "                     clip_norm_base, do_pred, curv_beta, param_beta, train_single_step, sliding_win_width, display_interval, test_interval, log_dir=log_dir)\n",
    "np.savetxt(log_dir + \"/loss_full.txt\", np.array(loss_list) )\n",
    "np.savetxt(log_dir + \"/g_norm_full.txt\", np.array(g_norm_list) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_val = 0.1\n",
    "mom_val = 0.9\n",
    "do_pred = True\n",
    "log_dir = general_log_dir + \"/two_term_lr_\" + str(lr_val) + \"_mom_\" + str(mom_val) + \"_exp_0.99\"\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "mon_sess.run(init_op)\n",
    "\n",
    "train_single_step = lambda lr_val, mom_val, clip_norm_base: train_single_step_frame(mon_sess, model_train, lr_val, mom_val, clip_norm_base)\n",
    "\n",
    "loss_list, g_norm_list = train_rave_noisy_acc(mon_sess, model_eval, num_step, lr_val, mom_val, \n",
    "                     clip_norm_base, do_pred, curv_beta, param_beta, train_single_step, sliding_win_width, display_interval, test_interval, log_dir=log_dir)\n",
    "np.savetxt(log_dir + \"/loss_full.txt\", np.array(loss_list) )\n",
    "np.savetxt(log_dir + \"/g_norm_full.txt\", np.array(g_norm_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_val = 0.01\n",
    "mom_val = 0.0\n",
    "do_pred = True\n",
    "log_dir = general_log_dir + \"/two_term_lr_\" + str(lr_val) + \"_mom_\" + str(mom_val) + \"_exp_0.99\"\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "mon_sess.run(init_op)\n",
    "\n",
    "train_single_step = lambda lr_val, mom_val, clip_norm_base: train_single_step_frame(mon_sess, model_train, lr_val, mom_val, clip_norm_base)\n",
    "\n",
    "loss_list, g_norm_list = train_rave_noisy_acc(mon_sess, model_eval, num_step, lr_val, mom_val, \n",
    "                     clip_norm_base, do_pred, curv_beta, param_beta, train_single_step, sliding_win_width, display_interval, test_interval, log_dir=log_dir)\n",
    "np.savetxt(log_dir + \"/loss_full.txt\", np.array(loss_list) )\n",
    "np.savetxt(log_dir + \"/g_norm_full.txt\", np.array(g_norm_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_val = 0.1\n",
    "mom_val = 0.0\n",
    "do_pred = True\n",
    "log_dir = general_log_dir + \"/two_term_lr_\" + str(lr_val) + \"_mom_\" + str(mom_val) + \"_exp_0.99\"\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "mon_sess.run(init_op)\n",
    "\n",
    "train_single_step = lambda lr_val, mom_val, clip_norm_base: train_single_step_frame(mon_sess, model_train, lr_val, mom_val, clip_norm_base)\n",
    "\n",
    "loss_list, g_norm_list = train_rave_noisy_acc(mon_sess, model_eval, num_step, lr_val, mom_val, \n",
    "                     clip_norm_base, do_pred, curv_beta, param_beta, train_single_step, sliding_win_width, display_interval, test_interval, log_dir=log_dir)\n",
    "np.savetxt(log_dir + \"/loss_full.txt\", np.array(loss_list) )\n",
    "np.savetxt(log_dir + \"/g_norm_full.txt\", np.array(g_norm_list) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
